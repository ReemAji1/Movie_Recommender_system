---
title: "Recommender_System"
author: "Reem Aji"
date: "07/07/2020"
output: html_document
---
#the folloiwng libraries will be used in this project:
```{r libs, warning=FALSE, error=FALSE, message=FALSE}
library(recommenderlab)
library(ggplot2)
library(data.table)
library(reshape2)
```

#Retrieving the Data

```{r data_load, warning=FALSE, error=FALSE, echo=FALSE}
movies <- read.csv("/Users/reemaji/Downloads/IMDB-Dataset/movies.csv")
ratings <- read.csv("/Users/reemaji/Downloads/IMDB-Dataset/ratings.csv")
```

#Summary and head for movies

```{r mov_summ, warning=FALSE, error=FALSE, echo=FALSE}
summary(ratings)
head(ratings)
```

#Summary and head for ratings:
```{r rat_summ, warning=FALSE, error=FALSE, echo=FALSE}
summary(ratings)
head(ratings)
```

#We observed that the userId column, as well as the movieId column, consist of integers.I will deal with this in the next step

#Data Pre-processing
#Extract a list of genres
#We need to convert the genres present in the movie_data dataframe into a more usable format by the users. In order to do so, we will first create a one-hot encoding to create a matrix that comprises of corresponding genres for each of the films.

```{r data_genres, warning=FALSE, error=FALSE, echo=FALSE}
genres <- as.data.frame(movies$genres, stringsAsFactors=FALSE)
genres2 <- as.data.frame(tstrsplit(genres[,1], '[|]', 
                                   type.convert=TRUE), 
                         stringsAsFactors=FALSE)
colnames(genres2) <- c(1:10)
genre_list <- c("Action", "Adventure", "Animation", "Children", 
                "Comedy", "Crime","Documentary", "Drama", "Fantasy",
                "Film-Noir", "Horror", "Musical", "Mystery","Romance",
                "Sci-Fi", "Thriller", "War", "Western") # we have 18 genres in total
genre_matrix <- matrix(0,10330,18) #empty matrix, 10330=no of movies+1, 18=no of genres
genre_matrix[1,] <- genre_list #set first row to genre list
colnames(genre_matrix) <- genre_list #set column names to genre list
#iterate through matrix
for (i in 1:nrow(genres2)) {
  for (c in 1:ncol(genres2)) {
    genmat_col = which(genre_matrix[1,] == genres2[i,c])
    genre_matrix[i+1,genmat_col] <- 1
  }
}
#convert into dataframe
genre_matrix2 <- as.data.frame(genre_matrix[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (c in 1:ncol(genre_matrix2)) {
  genre_matrix2[,c] <- as.integer(genre_matrix2[,c])  #convert from characters to integers
} 
head(genre_matrix2)
```

##Create a search matrix to search for a movie by genre

```{r search_genres, warning=FALSE, error=FALSE, echo=FALSE}
search_matrix <- cbind(movies[,1:2], genre_matrix2)
head(search_matrix)
```
#We realize that each movie can correspond to either one or more than one genre.For example, Toy Story, which is an animated film also falls under the genres of Comedy, Fantasy, and Children.

###Converting ratings matrix in a proper format
#In order to use the ratings data for building a recommendation engine with recommenderlab, I convert rating matrix into a sparse matrix of type realRatingMatrix.

```{r rat_mat, warning=FALSE, error=FALSE, echo=FALSE}
#Create ratings matrix. Rows = userId, Columns = movieId
ratingMatrix <- dcast(ratings, userId~movieId, value.var = "rating", na.rm=FALSE)
ratingMatrix <- as.matrix(ratingMatrix[,-1]) #remove userIds
#Convert rating matrix into a recommenderlab sparse matrix
ratingMatrix <- as(ratingMatrix, "realRatingMatrix")
ratingMatrix
```

## Exploring Parameters of Recommendation Models

#The *recommenderlab* package contains some options for the recommendation algorithm:

```{r rec_overview, warning=FALSE, error=FALSE, echo=FALSE}
recommender_models <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommender_models)

lapply(recommender_models, "[[", "description")
```

#I will implement a single model in this project – Item Based Collaborative Filtering.Check the parameters of this model.

```{r model_param, warning=FALSE, error=FALSE}
recommender_models$IBCF_realRatingMatrix$parameters
```

## Exploring Similarity Data
#Collaborative Filtering involves suggesting movies to the users that are based on collecting preferences from many other users. For example, if a user A likes to watch action films and so does user B, then the movies that the user B will watch in the future will be recommended to A and vice-versa. Therefore, recommending movies is dependent on creating a relationship of similarity between the two users. With the help of recommenderlab, we can compute similarities using various operators like cosine, pearson as well as jaccard.

#Now, I determine how similar the first four users are with each other by creating and visualizing similarity matrix that uses the cosine distance:

```{r sim_users, warning=FALSE, error=FALSE, echo=FALSE}
similarity_users <- similarity(ratingMatrix[1:4, ], 
                               method = "cosine", 
                               which = "users")
as.matrix(similarity_users)
image(as.matrix(similarity_users), main = "User similarity")
```
#in the givin matrix, each row and column represents a user. We have taken four users and each cell in this matrix represents the similarity that is shared between the two users.


##Using the same approach, I compute similarity between the first four movies.
```{r sim_movies, warning=FALSE, error=FALSE, echo=FALSE}
movie_similarity <- similarity(ratingMatrix[, 1:4], method =
                                 "cosine", which = "items")
as.matrix(movie_similarity)
image(as.matrix(movie_similarity), main = "Movies similarity")
```

#Further Data Exploration 
#now I extract the most unique ratings 
```{r rate_values, warning=FALSE, error=FALSE}
rating_values <- as.vector(ratingMatrix@data)
unique(rating_values) #extracting unique ratings

#now I create a table of ratings to display the most unique ratings
table_ratings <- table(vector_ratings) # what is the count of each rating value
table_ratings
```
#from the table we realize that there are 11 unique score values. The lower values mean lower ratings and vice versa.

#Distribution of the ratings

#rating = 0 represent a missing value, so I'll remove them from the dataset before visualizing the results
```{r rat_distrib, warning=FALSE, error=FALSE, echo=FALSE}

rating_values <- rating_values[rating_values != 0]
rating_values <- factor(rating_values)

qplot(rating_values) + 
  ggtitle("Distribution of the ratings")
```
#we can see that the most common rating is 4. The majority of movies are rated with 3 or higher. 

#now,let's see nuumber of views of the top movies
#We will first count the number of views in a film and then organize them in a table that would group them in descending order

```{r top_no, warning=FALSE, error=FALSE, echo=FALSE}
moview_views <- colCounts(ratingMatrix) #count views for each movie
table_views <- data.frame(movie = names(moview_views),
                          views = moview_views) #create dataframe of views
table_views <- table_views[order(table_views$views, 
                                 decreasing = TRUE), ] # sort by number of views
table_views$title <- NA
for (i in 1:10325){
  table_views[i,3] <- as.character(subset(movies, 
                                          movies$movieId == table_views[i,1])$title)
}
table_views[1:6,]

#Now, we will visualize a bar plot for the total number of views of the top films using ggplot2.

ggplot(table_views[1:6, ], aes(x = title, y = views)) +
  geom_bar(stat="identity", fill = 'steelblue') +
  geom_text(aes(label=views), vjust=-0.3, size=3.5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Total views of top movies")
```
#We see that "Pulp Fiction (1994)" is the most viewed movie, exceeding the second-most-viewed "Forrest Gump (1994)" by 14 views.

### Distribution of the average movie rating
#Now I identify the top-rated movies by computing the average rating of each of them.
```{r avg_rat, warning=FALSE, error=FALSE, echo=FALSE, message=FALSE}
average_ratings <- colMeans(ratingMatrix)
qplot(average_ratings) + 
  stat_bin(binwidth = 0.1) +
  ggtitle("Distribution of the average movie rating")
average_ratings_relevant <- average_ratings[views_per_movie > 50] 
qplot(average_ratings_relevant) + 
  stat_bin(binwidth = 0.1) +
  ggtitle(paste("Distribution of the relevant average ratings"))
```

### Heatmap of the rating matrix
# visualize the matrix of ratings by building a heat map whose colors represent the ratings. Each row of the matrix corresponds to a user, each column to a movie, and each cell to its rating.

```{r heat_rate, warning=FALSE, error=FALSE, echo=FALSE}
image(ratingMatrix, main = "Heatmap of the rating matrix") # hard to read-too many dimensions
image(ratingMatrix[1:20, 1:25], main = "Heatmap of the first 20 rows and 25 columns")
```

#Since there are too many users and items, the first chart is hard to read. The second chart is built zooming in on the first rows and columns.

# We should selecet the more relevant users and items since some users saw more movies than the others. Therfore, I  visualize only the users who have seen many movies and the movies that have been seen by many users by following these steps:Determine the minimum number of movies per user.Then, determine the minimum number of users per movie.Finally, select the users and movies matching these criteria.

```{r heat_relev, warning=FALSE, error=FALSE, echo=FALSE}
min_n_movies <- quantile(rowCounts(ratingMatrix), 0.99)
min_n_users <- quantile(colCounts(ratingMatrix), 0.99)
print("Minimum number of movies per user:")
min_n_movies
print("Minimum number of users per movie:")
min_n_users
image(ratingmat[rowCounts(ratingMatrix) > min_n_movies,
                 colCounts(ratingMatrix) > min_n_users], 
main = "Heatmap of the top users and movies")
```

#Data Preparation 

##Select the relevant data
#In order to select the most relevant data, I define the minimum number of users per rated movie as 50 and the minimum views number per movie as 50:
```{r rel_data, warning=FALSE, error=FALSE, echo=FALSE}

ratings_movies <- ratingMatrix[rowCounts(ratingMatrix) > 50,
                               colCounts(ratingMatrix) > 50]
ratings_movies
```
#Such a selection of the most relevant data contains 420 users and 447 movies, compared to previous 668 users and 10325 movies in the total dataset.

#Using the same approach as previously, I visualize the top 2 percent of users and movies in the new matrix of the most relevant data:
```{r rel_explore, warning=FALSE, error=FALSE, echo=FALSE}
min_movies <- quantile(rowCounts(ratings_movies), 0.98)
min_users <- quantile(colCounts(ratings_movies), 0.98)
image(ratings_movies[rowCounts(ratings_movies) > min_movies,
                     colCounts(ratings_movies) > min_users], 
      main = "Heatmap of the top users and movies")

average_ratings_per_user <- rowMeans(ratings_movies)
qplot(average_ratings_per_user) + stat_bin(binwidth = 0.1) +
  ggtitle("Distribution of the average rating per user")
```

#Normalizong data

##Having users who give high (or low) ratings to all their movies might bias the results. In order to remove this effect, I normalize the data so that the average rating of each user is 0. As a quick check, I calculate the average rating by users, and it is equal to 0, as expected:

```{r normal_data, warning=FALSE, error=FALSE}
ratings_movies_norm <- normalize(ratings_movies)
sum(rowMeans(ratings_movies_norm) > 0.00001)
```

#plot a heatmap that delineates our normalized ratings.

```{r viz_normal_data, warning=FALSE, error=FALSE, echo=FALSE}
image(ratings_movies_norm[rowCounts(ratings_movies_norm) > min_movies,
                          colCounts(ratings_movies_norm) > min_users], 
main = "Heatmap of the top users and movies")

```
##Binarizing data 

#Binarizing the data means that we have two discrete values 1 and 0, which will allow our recommendation systems to work more efficiently. We will define a matrix that will consist of 1 if the rating is above 3 and otherwise it will be 0.

#I define the matrice and visualize a 5 percent portion of it.

```{r binar_data, warning=FALSE, error=FALSE, echo=FALSE}
ratings_movies_good <- binarize(ratings_movies, minRating = 3)
min_movies_binary <- quantile(rowCounts(ratings_movies), 0.95)
min_users_binary <- quantile(colCounts(ratings_movies), 0.95)
image(ratings_movies_good[rowCounts(ratings_movies) > min_movies_binary, 
                          colCounts(ratings_movies) > min_users_binary], 
      main = "Heatmap of the top users and movies")
```

##Item-based collaborative Filtering Model 
#now, we build the filtering system by splitting the dataset into 80% training set and 20% test set

```{r train_test_sets, warning=FALSE, message=FALSE, echo=FALSE}
splitting_data <- sample(x = c(TRUE, FALSE),
                         size = nrow(ratings_movies),
                         replace = TRUE,
                         prob = c(0.8, 0.2))
training_data <- ratings_movies[splitting_data, ]
testing_data <- ratings_movies[!splitting_data, ]
```

#now, I build the recommendation model
```{r build_recommenderIBCF, warning=FALSE, message=FALSE, echo=FALSE}
recommender_models <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
recommender_models$IBCF_realRatingMatrix$parameters

recc_model <- Recommender(data = training_data,
                          method = "IBCF",
                          parameter = list(k=30))

recc_model
class(recc_model)
```

#Exploring the recommendation model
```{r explore_IBCF, warning=FALSE, message=FALSE, echo=FALSE}
model_info <- getModel(recc_model)
class(model_info$sim) #contains a similiraty matrix
dim(model_info$sim)
top_items <- 20 
image(model_info$sim[1:top_items, 1:top_items],
      main = "Heatmap of the first rows and columns")

#sum of row and columns with similarity and visualize them

sum_rows <- rowSums(model_info$sim > 0)
table(sum_rows)
sum_cols <- colSums(model_info$sim > 0)
qplot(sum_cols, fill=I("steelblue"), col=I("red"))+ ggtitle("Distribution of the column count")
```

## Applying recommender system on the dataset:
```{r apply_IBCF, warning=FALSE, message=FALSE, echo=FALSE}
n_recommended <- 10 # the number of items to recommend to each user
recc_predicted <- predict(object = recc_model, 
                          newdata = testing_data, 
                          n = n_recommended)
recc_predicted

#explore the result of the recommendation model for the first user

user_1 <- recc_predicted@items[[1]] # recommendation for the first user
movies_user_1 <- recc_predicted@itemLabels[user_1]
movies_user_2 <- movies_user_1
for (i in 1:10){
  movies_user_2[i] <- as.character(subset(movies, 
                                          movies$movieId == movies_user_1[i])$title)
}
movies_user_2
```

#define a matrix with the recommendations for each user. visualize the recommendations for the first four users
```{r recc_matrix, warning=FALSE, message=FALSE, echo=FALSE}
recc_matrix <- sapply(recc_predicted@items, 
                      function(x){ as.integer(colnames(ratings_movies)[x]) }) # matrix with the recommendations for each user
#dim(recc_matrix)
recc_matrix[,1:4]
```
#the columns represent the first 4 users, and the rows are the *movieId* values of recommended 10 movies

#let’s identify the most recommended movies. The following image shows the distribution of the number of items for IBCF:

```{r most_recom_moviesIBCF, warning=FALSE, message=FALSE, echo=FALSE}
number_of_items <- factor(table(recc_matrix))
chart_title <- "Distribution of the number of items for IBCF"
qplot(number_of_items) + ggtitle(chart_title)
number_of_items_sorted <- sort(number_of_items, decreasing = TRUE)
number_of_items_top <- head(number_of_items_sorted, n = 4)
table_top <- data.frame(as.integer(names(number_of_items_top)),
                        number_of_items_top)
for (i in 1:4){
  table_top[i,1] <- as.character(subset(movies, 
                                        movies$movieId == table_top[i,1])$title)
}
colnames(table_top) <- c("Movie title", "No of items")
head(table_top)
```
#we can see that most of the movies have been recommended only a few times, and a few movies have been recommended more than 5 times.

#Conclusion
##IBCF recommends items on the basis of the similarity matrix. It’s an eager-learning model, once built, it doesn’t need to access the initial data.In addition, this algorithm is efficient and scalable, so it works well with big rating matrices.
